# yamllint disable rule:line-length rule:indentation
---
name: Release

on:
  push:
    branches: [main]
    tags: ['v*.*.*']
  workflow_dispatch:
    inputs:
      target:
        description: "Deploy target (mac=self-hosted, ec2=remote EC2)"
        type: choice
        options: [mac, ec2]
        default: mac
      use_existing_images:
        description: "Skip builds and use an existing image tag"
        type: boolean
        default: false
      image_tag:
        description: "Existing image tag to deploy (required when skipping builds)"
        type: string
        default: ""
      run_snyk:
        description: "Run Snyk scan (pulls images; may hit rate limits)"
        type: boolean
        default: true

permissions:
  contents: write
  packages: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # ------------------------------------------------------------
  # Resolve deploy target once (input > org/repo var > default)
  # ------------------------------------------------------------
  resolve-target:
    name: Resolve deploy target
    runs-on: ubuntu-latest
    outputs:
      target: ${{ steps.out.outputs.target }}
    steps:
      - id: out
        shell: bash
        run: |
          in="${{ inputs.target }}"
          var="${{ vars.DEPLOY_TARGET }}"
          tgt="${in:-${var:-mac}}"
          echo "target=$tgt" >> "$GITHUB_OUTPUT"
          echo "Deploy target resolved to: $tgt"

  # ----------------------------------------------------------
  # Tag computation: continue v*.*.* series (patch bumps)
  # ----------------------------------------------------------
  compute-tag:
    name: Compute next tag (when pushing to main)
    runs-on: ubuntu-latest
    if: ${{ github.ref_type == 'branch' && github.ref_name == 'main' }}
    outputs:
      tag: ${{ steps.bump.outputs.tag }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - name: Compute next tag (no create)
        id: bump
        shell: bash
        run: |
          set -euo pipefail
          git fetch --tags --force
          last="$(git tag -l 'v*.*.*' | sort -V | tail -n1 || true)"
          if [[ -z "$last" ]]; then
            major=1 minor=0 patch=1
          else
            IFS=. read -r vM vN vP <<<"${last#v}"
            major="$vM"; minor="$vN"; patch="$vP"
            patch=$((10#$patch + 1))
          fi
          echo "tag=v${major}.${minor}.${patch}" >> "$GITHUB_OUTPUT"
          echo "Next tag: v${major}.${minor}.${patch}"

  # ----------------------------------------------------------
  # Decide IMAGE_TAG & whether we build or reuse images
  # ----------------------------------------------------------
  resolve-build-mode:
    name: Resolve image tag & build mode
    runs-on: ubuntu-latest
    needs: [compute-tag]
    outputs:
      IMAGE_TAG: ${{ steps.out.outputs.IMAGE_TAG }}
      BUILD_IMAGES: ${{ steps.out.outputs.BUILD_IMAGES }}
      RUN_SNYK: ${{ steps.out.outputs.RUN_SNYK }}
    steps:
      - id: out
        shell: bash
        run: |
          set -euo pipefail
          if [[ "${{ inputs.use_existing_images }}" == "true" ]]; then
            BUILD="false"
          else
            BUILD="true"
          fi

          if [[ "${{ github.ref_type }}" == "tag" ]]; then
            TAG="${{ github.ref_name }}"
          elif [[ -n "${{ inputs.image_tag }}" ]]; then
            TAG="${{ inputs.image_tag }}"
          else
            TAG="${{ needs.compute-tag.outputs.tag }}"
          fi

          if [[ "$BUILD" == "false" && "${{ github.ref_type }}" != "tag" && -z "${{ inputs.image_tag }}" ]]; then
            echo "::error::use_existing_images=true but no image_tag was provided."
            exit 1
          fi

          if [[ "${{ inputs.run_snyk }}" == "true" ]]; then RUN_SNYK="true"; else RUN_SNYK="false"; fi

          echo "IMAGE_TAG=$TAG"       >> "$GITHUB_OUTPUT"
          echo "BUILD_IMAGES=$BUILD"  >> "$GITHUB_OUTPUT"
          echo "RUN_SNYK=$RUN_SNYK"   >> "$GITHUB_OUTPUT"
          echo "Resolved: IMAGE_TAG=$TAG · BUILD_IMAGES=$BUILD · RUN_SNYK=$RUN_SNYK"

  # ----------------------------------------------------------
  # Bump helm appVersions on main
  # ----------------------------------------------------------
  bump-helm-appversion:
    name: Bump Helm appVersion in all charts & push
    runs-on: ubuntu-latest
    needs: [compute-tag]
    if: ${{ github.ref_type == 'branch' && github.ref_name == 'main' }}
    env:
      TAG: ${{ needs.compute-tag.outputs.tag }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - name: Install yq (static)
        run: |
          set -euo pipefail
          YQ_VERSION=v4.44.3
          OS=$(uname); ARCH=$(uname -m)
          case "$ARCH" in x86_64) ARCH=amd64;; aarch64|arm64) ARCH=arm64;; esac
          curl -fsSL -o /usr/local/bin/yq "https://github.com/mikefarah/yq/releases/download/${YQ_VERSION}/yq_${OS}_${ARCH}"
          chmod +x /usr/local/bin/yq
      - name: Update appVersion for ALL charts + write releaseTag
        shell: bash
        run: |
          set -euo pipefail
          mapfile -t charts < <(git ls-files 'infra/helm/**/Chart.yaml')
          (( ${#charts[@]} )) || { echo "No Chart.yaml under infra/helm"; exit 1; }
          for f in "${charts[@]}"; do
            yq -i '.appVersion = env(TAG)' "$f"
          done
          yq -i '.global.releaseTag = env(TAG)' infra/helm/argocd-apps/values.yaml
      - name: Commit & push change
        run: |
          set -euo pipefail
          git config user.name  "github-actions"
          git config user.email "github-actions@users.noreply.github.com"
          if git diff --quiet; then
            echo "No changes to commit."
          else
            git add infra/helm/**/Chart.yaml infra/helm/argocd-apps/values.yaml
            git commit -m "chore(helm): set appVersion & releaseTag ${TAG}"
            git push origin HEAD:main
          fi

  create-tag:
    name: Create & push git tag
    runs-on: ubuntu-latest
    needs: [compute-tag, bump-helm-appversion]
    if: ${{ github.ref_type == 'branch' && github.ref_name == 'main' }}
    env:
      TAG: ${{ needs.compute-tag.outputs.tag }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - name: Configure git identity
        run: |
          git config user.name  "github-actions"
          git config user.email "github-actions@users.noreply.github.com"
      - name: Tag & push
        shell: bash
        run: |
          set -euo pipefail
          git fetch --all --tags
          git checkout main
          git pull --ff-only
          if git rev-parse "$TAG" >/dev/null 2>&1; then
            echo "Tag $TAG already exists; skipping create."
          else
            git tag -a "$TAG" -m "Release $TAG"
            git push origin "$TAG"
          fi

  # ----------------------------------------------------------
  # Build & push APP image (multi-arch) — gated
  # ----------------------------------------------------------
  build-and-push-app:
    name: Build & push app image
    runs-on: ubuntu-latest
    needs: [resolve-build-mode]
    if: ${{ needs.resolve-build-mode.outputs.BUILD_IMAGES == 'true' }}
    env:
      IMAGE_TAG: ${{ needs.resolve-build-mode.outputs.IMAGE_TAG }}
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
      DOCKERHUB_REPO_APP: ${{ secrets.DOCKERHUB_REPO_APP }}
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - name: Login to Docker Hub
        if: ${{ env.DOCKERHUB_USERNAME != '' && env.DOCKERHUB_TOKEN != '' }}
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKERHUB_USERNAME }}
          password: ${{ env.DOCKERHUB_TOKEN }}
      - name: Build & push (linux/amd64, linux/arm64)
        uses: docker/build-push-action@v6
        with:
          context: ./app
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ env.DOCKERHUB_REPO_APP }}:${{ env.IMAGE_TAG }}

  # ----------------------------------------------------------
  # Build & push WEB image (multi-arch) — gated
  # ----------------------------------------------------------
  build-and-push-web:
    name: Build & push web image
    runs-on: ubuntu-latest
    needs: [resolve-build-mode]
    if: ${{ needs.resolve-build-mode.outputs.BUILD_IMAGES == 'true' }}
    env:
      IMAGE_TAG: ${{ needs.resolve-build-mode.outputs.IMAGE_TAG }}
      DOCKERHUB_USERNAME: ${{ secrets.DOCKERHUB_USERNAME }}
      DOCKERHUB_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
      DOCKERHUB_REPO_WEB: ${{ secrets.DOCKERHUB_REPO_WEB }}
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - name: Login to Docker Hub
        if: ${{ env.DOCKERHUB_USERNAME != '' && env.DOCKERHUB_TOKEN != '' }}
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKERHUB_USERNAME }}
          password: ${{ env.DOCKERHUB_TOKEN }}
      - name: Build & push (linux/amd64, linux/arm64)
        uses: docker/build-push-action@v6
        with:
          context: ./web
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ env.DOCKERHUB_REPO_WEB }}:${{ env.IMAGE_TAG }}

  # ----------------------------------------------------------
  # Snyk (optional)
  # ----------------------------------------------------------
  snyk-release:
    name: Snyk scan of images
    runs-on: ubuntu-latest
    needs: [resolve-build-mode, build-and-push-app, build-and-push-web]
    if: ${{ needs.resolve-build-mode.outputs.RUN_SNYK == 'true' }}
    env:
      IMAGE_TAG: ${{ needs.resolve-build-mode.outputs.IMAGE_TAG }}
      SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
      DOCKERHUB_REPO_APP: ${{ secrets.DOCKERHUB_REPO_APP }}
      DOCKERHUB_REPO_WEB: ${{ secrets.DOCKERHUB_REPO_WEB }}
    steps:
      - uses: actions/checkout@v4
      - uses: snyk/actions/setup@0.4.0
      - run: snyk auth "$SNYK_TOKEN"
      - name: Build .snyk from ignore list (if present)
        shell: bash
        run: |
          set -euo pipefail
          touch .snyk
          if [[ -f "security/ignores.txt" ]]; then
            grep -v '^\s*#' security/ignores.txt | sed '/^\s*$/d' | while read -r ID; do
              snyk ignore --id="$ID" --reason="approved via repo ignore list" --expiry=2099-12-31 --yes --quiet || true
            done
          fi
      - name: Scan & save JSON
        id: scan
        shell: bash
        run: |
          set +e
          set -u -o pipefail
          printf "%s\n" \
            "${DOCKERHUB_REPO_APP}:${IMAGE_TAG}" \
            "${DOCKERHUB_REPO_WEB}:${IMAGE_TAG}" > images.txt
          failures=0
          while read -r IMG; do
            [[ -z "$IMG" ]] && continue
            SAFE="$(echo "$IMG" | tr '/:@' '___')"
            OUT="snyk-${SAFE}.json"
            snyk container test "$IMG" --severity-threshold=high --json-file-output="$OUT"
            rc=$?
            if [ ! -s "$OUT" ]; then
              snyk container test "$IMG" --severity-threshold=high --json > "$OUT" 2>/dev/null || echo '{"note":"no json"}' > "$OUT"
            fi
            if [ $rc -ne 0 ]; then failures=$((failures+1)); fi
          done < images.txt
          echo "failures=$failures" >> "$GITHUB_OUTPUT"
      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: snyk-reports
          path: snyk-*.json
          if-no-files-found: warn
      - name: Fail if any image failed
        if: ${{ steps.scan.outputs.failures != '0' }}
        run: |
          echo "Blocking release: Snyk found issues above threshold."
          exit 1

  # ----------------------------------------------------------
  # Mirror to local Nexus (Mac) — separate stage
  # ----------------------------------------------------------
  mirror-to-nexus:
    name: Mirror to local Nexus
    runs-on: [self-hosted, macOS]
    needs: [resolve-target, resolve-build-mode, build-and-push-app, build-and-push-web]
    if: ${{ needs.resolve-target.outputs.target == 'mac' && vars.DEPLOY_REGISTRY == 'nexus' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) }}
    env:
      TAG: ${{ needs.resolve-build-mode.outputs.IMAGE_TAG }}
      DOCKERHUB_REPO_APP: ${{ secrets.DOCKERHUB_REPO_APP }}
      DOCKERHUB_REPO_WEB: ${{ secrets.DOCKERHUB_REPO_WEB }}
      DH_USER: ${{ secrets.DOCKERHUB_USERNAME }}
      DH_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}
      NEXUS_DOMAIN: ${{ secrets.NEXUS_REGISTRY_DOMAIN }}   # e.g. 127.0.0.1:5000
      NEXUS_USER: ${{ secrets.NEXUS_USERNAME }}
      NEXUS_PASS: ${{ secrets.NEXUS_PASSWORD }}
      NEXUS_REPO_APP: ${{ secrets.NEXUS_REPO_APP }}
      NEXUS_REPO_WEB: ${{ secrets.NEXUS_REPO_WEB }}
    steps:
      - uses: actions/checkout@v4
      - name: Install skopeo (brew)
        shell: bash
        run: |
          set -euo pipefail
          if ! command -v skopeo >/dev/null 2>&1; then
            brew update
            brew install skopeo
          fi
      - name: Verify images exist on Hub
        shell: bash
        run: |
          set -euo pipefail
          for IMG in "${DOCKERHUB_REPO_APP}:${TAG}" "${DOCKERHUB_REPO_WEB}:${TAG}"; do
            echo "Checking $IMG"
            if ! docker buildx imagetools inspect "$IMG" >/dev/null 2>&1; then
              echo "::error::Image not found on Hub: $IMG"
              exit 1
            fi
          done
      - name: Mirror both images with skopeo
        shell: bash
        run: |
          set -euo pipefail
          SRC_APP="docker://${DOCKERHUB_REPO_APP}:${TAG}"
          SRC_WEB="docker://${DOCKERHUB_REPO_WEB}:${TAG}"
          DST_APP="docker://${NEXUS_DOMAIN}/${NEXUS_REPO_APP}:${TAG}"
          DST_WEB="docker://${NEXUS_DOMAIN}/${NEXUS_REPO_WEB}:${TAG}"
          for S D in "$SRC_APP" "$DST_APP" "$SRC_WEB" "$DST_WEB"; do :; done
          skopeo copy --src-creds "${DH_USER}:${DH_TOKEN}" --dest-creds "${NEXUS_USER}:${NEXUS_PASS}" \
                      --src-tls-verify=true --dest-tls-verify=false "${SRC_APP}" "${DST_APP}"
          skopeo copy --src-creds "${DH_USER}:${DH_TOKEN}" --dest-creds "${NEXUS_USER}:${NEXUS_PASS}" \
                      --src-tls-verify=true --dest-tls-verify=false "${SRC_WEB}" "${DST_WEB}"
          # Also tag latest
          skopeo copy --src-creds "${DH_USER}:${DH_TOKEN}" --dest-creds "${NEXUS_USER}:${NEXUS_PASS}" \
                      --src-tls-verify=true --dest-tls-verify=false "${SRC_APP}" "docker://${NEXUS_DOMAIN}/${NEXUS_REPO_APP}:latest"
          skopeo copy --src-creds "${DH_USER}:${DH_TOKEN}" --dest-creds "${NEXUS_USER}:${NEXUS_PASS}" \
                      --src-tls-verify=true --dest-tls-verify=false "${SRC_WEB}" "docker://${NEXUS_DOMAIN}/${NEXUS_REPO_WEB}:latest"

  # ----------------------------------------------------------
  # Deploy to EC2 (kept for compatibility)
  # ----------------------------------------------------------
  deploy-ec2:
    name: Deploy to EC2
    runs-on: ubuntu-latest
    needs: [resolve-target, resolve-build-mode, build-and-push-app, build-and-push-web, snyk-release, create-tag]
    if: ${{ needs.resolve-target.outputs.target == 'ec2' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) }}
    steps:
      - run: echo "EC2 flow skipped/placeholder."

  # ----------------------------------------------------------
  # Deploy to Mac (self-hosted) — supports Hub or local Nexus
  # ----------------------------------------------------------
  deploy-mac:
    name: Deploy on Mac (self-hosted)
    runs-on: [ self-hosted, macOS ]
    needs: [resolve-target, resolve-build-mode, build-and-push-app, build-and-push-web, snyk-release, mirror-to-nexus, create-tag]
    if: ${{ needs.resolve-target.outputs.target == 'mac' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) }}
    env:
      # Version/tag to deploy
      TAG: ${{ needs.resolve-build-mode.outputs.IMAGE_TAG }}

      # Hub repos + creds
      DOCKERHUB_REPO_APP: ${{ secrets.DOCKERHUB_REPO_APP }}
      DOCKERHUB_REPO_WEB: ${{ secrets.DOCKERHUB_REPO_WEB }}
      DH_USER: ${{ secrets.DOCKERHUB_USERNAME }}
      DH_TOKEN: ${{ secrets.DOCKERHUB_TOKEN }}

      # Switch to pull from Nexus by setting DEPLOY_REGISTRY=nexus
      REGISTRY_KIND: ${{ vars.DEPLOY_REGISTRY }}

      # Local Nexus on the Mac
      NEXUS_DOMAIN: ${{ secrets.NEXUS_REGISTRY_DOMAIN }}     # e.g. 127.0.0.1:5000
      NEXUS_USER: ${{ secrets.NEXUS_USERNAME }}
      NEXUS_PASS: ${{ secrets.NEXUS_PASSWORD }}
      NEXUS_REPO_APP: ${{ secrets.NEXUS_REPO_APP }}
      NEXUS_REPO_WEB: ${{ secrets.NEXUS_REPO_WEB }}

      # App/DB runtime config
      DB_NAME: ${{ vars.DB_NAME }}
      DB_USER: ${{ vars.DB_USER }}
      DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      DB_PORT: ${{ vars.DB_PORT }}
      FLASK_PORT: ${{ vars.FLASK_PORT }}
      WEB_PORT: ${{ vars.WEB_PORT || '8082' }}

    steps:
      - uses: actions/checkout@v4

      - name: Decide image sources (Hub or Nexus) & write .env.local
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p mac-release-flow

          if [[ "${REGISTRY_KIND:-hub}" == "nexus" ]]; then
            IMAGE_REPO_APP="${NEXUS_DOMAIN}/${NEXUS_REPO_APP}"
            IMAGE_REPO_WEB="${NEXUS_DOMAIN}/${NEXUS_REPO_WEB}"
          else
            IMAGE_REPO_APP="${DOCKERHUB_REPO_APP}"
            IMAGE_REPO_WEB="${DOCKERHUB_REPO_WEB}"
          fi

          : "${IMAGE_REPO_APP:?IMAGE_REPO_APP is empty}"
          : "${IMAGE_REPO_WEB:?IMAGE_REPO_WEB is empty}"
          : "${TAG:?TAG is empty}"

          cat > mac-release-flow/.env.local <<EOF
          DOCKERHUB_REPO_APP=${IMAGE_REPO_APP}
          DOCKERHUB_REPO_WEB=${IMAGE_REPO_WEB}
          TAG=${TAG}
          WEB_PORT=${WEB_PORT}
          DB_NAME=${DB_NAME}
          DB_USER=${DB_USER}
          DB_PASSWORD=${DB_PASSWORD}
          DB_PORT=${DB_PORT}
          FLASK_PORT=${FLASK_PORT}
          EOF

          echo "Using image sources:"
          sed -n '1,8p' mac-release-flow/.env.local

      - name: Login to Docker Hub (pull fallback)
        if: ${{ env.DH_USER != '' && env.DH_TOKEN != '' }}
        run: echo "${DH_TOKEN}" | docker login -u "${DH_USER}" --password-stdin

      - name: Login to local Nexus registry (only if REGISTRY_KIND=nexus)
        if: ${{ env.REGISTRY_KIND == 'nexus' && env.NEXUS_DOMAIN != '' && env.NEXUS_USER != '' && env.NEXUS_PASS != '' }}
        run: echo "${NEXUS_PASS}" | docker login "${NEXUS_DOMAIN}" -u "${NEXUS_USER}" --password-stdin

      - name: Ensure volume & pre-pull images (best effort)
        shell: bash
        run: |
          set -euo pipefail
          docker volume create supermario_db_data >/dev/null
          APP_REPO="$(grep '^DOCKERHUB_REPO_APP=' mac-release-flow/.env.local | cut -d= -f2)"
          WEB_REPO="$(grep '^DOCKERHUB_REPO_WEB=' mac-release-flow/.env.local | cut -d= -f2)"
          docker pull "${APP_REPO}:${TAG}" || true
          docker pull "${WEB_REPO}:${TAG}" || true

      - name: Compose up on Mac
        run: |
          docker compose \
            --env-file mac-release-flow/.env.local \
            -f mac-release-flow/deploy/compose.local.yml up -d --no-build
          docker ps --format 'table {{.Names}}\t{{.Status}}\t{{.Ports}}'

  # ----------------------------------------------------------
  # Prepare Minikube (no downgrade) + Argo CD (idempotent)
  # ----------------------------------------------------------
  prepare-minikube:
    name: Prepare Minikube & Argo CD
    runs-on: [ self-hosted, macOS ]
    if: ${{ needs.resolve-target.outputs.target == 'mac' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) }}
    needs: [resolve-target]
    env:
      MK_CPUS: "4"
      MK_MEMORY: "6g"
      MK_DRIVER: docker
      ARGO_NS: argocd
      ARGO_VERSION: "v2.11.7"
    steps:
      - uses: actions/checkout@v4
      - name: Ensure kubectl, helm, minikube
        shell: bash
        run: |
          set -euo pipefail
          command -v kubectl  >/dev/null || brew install kubernetes-cli
          command -v helm     >/dev/null || brew install helm
          command -v minikube >/dev/null || brew install minikube
          kubectl version --client=true
          helm version
          minikube version

      - name: Start/ensure Minikube (reuse existing; no downgrade)
        id: mkstart
        shell: bash
        env:
          MK_PROFILE: ${{ vars.MINIKUBE_PROFILE || 'minikube' }}
          MK_DRIVER:  ${{ vars.MINIKUBE_DRIVER  || 'docker' }}
          MK_CPUS:    ${{ vars.MINIKUBE_CPUS    || '4' }}
          MK_MEMORY:  ${{ vars.MINIKUBE_MEMORY  || '6g' }}
          MK_K8S_VER: ${{ vars.MINIKUBE_K8S_VERSION }}
        run: |
          set -euo pipefail
          echo "Profile=${MK_PROFILE}; driver=${MK_DRIVER}; cpus=${MK_CPUS}; mem=${MK_MEMORY}; requested_k8s=${MK_K8S_VER:-<none>}"
          is_running() { minikube status -p "${MK_PROFILE}" --output=json 2>/dev/null | grep -q '"Host": "Running"'; }
          current_version() {
            minikube -p "${MK_PROFILE}" kubectl -- get nodes -o jsonpath='{.items[0].status.nodeInfo.kubeletVersion}' 2>/dev/null || true
          }
          if is_running; then
            CUR_VER="$(current_version)"
            echo "Minikube already running. Current k8s: ${CUR_VER:-unknown}"
            if [[ -n "${MK_K8S_VER:-}" && -n "${CUR_VER:-}" && "${CUR_VER#v}" != "${MK_K8S_VER#v}" ]]; then
              echo "::warning::Requested ${MK_K8S_VER} != running ${CUR_VER}. Reusing existing cluster to avoid downgrade/upgrade."
            fi
          else
            ARGS=( -p "${MK_PROFILE}" --driver="${MK_DRIVER}" --cpus="${MK_CPUS}" --memory="${MK_MEMORY}" )
            if [[ -n "${MK_K8S_VER:-}" ]]; then ARGS+=( --kubernetes-version="${MK_K8S_VER}" ); fi
            echo "Starting: minikube start ${ARGS[*]}"
            set +e
            minikube start "${ARGS[@]}"
            RC=$?
            set -e
            if [[ $RC -ne 0 ]]; then
              echo "::warning::minikube start failed (rc=$RC). Retrying without --kubernetes-version to reuse default/current…"
              minikube start -p "${MK_PROFILE}" --driver="${MK_DRIVER}" --cpus="${MK_CPUS}" --memory="${MK_MEMORY}"
            fi
          fi
          kubectl config use-context "${MK_PROFILE}" >/dev/null 2>&1 || true
          kubectl get nodes -o wide || true

      - name: Enable addons (ingress, metrics)
        shell: bash
        run: |
          set -euo pipefail
          minikube addons enable ingress
          minikube addons enable metrics-server
          kubectl -n ingress-nginx rollout status deploy/ingress-nginx-controller --timeout=180s || \
          kubectl -n ingress-nginx rollout status deploy/ingress-nginx-controller-admission --timeout=180s || true

      - name: Preflight cleanup — remove non-Helm Argo CD Ingress
        shell: bash
        env:
          ARGO_NS: argocd
        run: |
          set -euo pipefail
          # Ensure namespace exists (idempotent)
          kubectl get ns "${ARGO_NS}" >/dev/null 2>&1 || kubectl create ns "${ARGO_NS}"

          # Delete the stray Ingress so Helm can create/own it
          kubectl -n "${ARGO_NS}" delete ingress argocd-server --ignore-not-found

          # (optional but harmless) make sure the Service is ClusterIP; Helm will manage it
          kubectl -n "${ARGO_NS}" patch svc argocd-server --type=merge -p '{"spec":{"type":"ClusterIP"}}' || true

      - name: Install/Upgrade Argo CD (Helm, pinned)
        shell: bash
        env:
          ARGO_NS: argocd
        run: |
          set -euo pipefail
          helm repo add argo https://argoproj.github.io/argo-helm
          helm repo update
          # Install chart but DO NOT create Ingress yet
          helm upgrade --install argocd argo/argo-cd \
            --version 6.7.12 \
            -n "${ARGO_NS}" --create-namespace \
            -f infra/helm/argocd/values-2-11.yaml \
            --set server.ingress.enabled=false \
            --set server.service.type=ClusterIP \
            --wait
            
          kubectl -n "${ARGO_NS}" rollout status deploy/argocd-repo-server --timeout=180s
          kubectl -n "${ARGO_NS}" rollout status deploy/argocd-server      --timeout=180s
          kubectl -n "${ARGO_NS}" rollout status statefulset/argocd-application-controller --timeout=180s || \
          kubectl -n "${ARGO_NS}" rollout status deploy/argocd-application-controller
          
          
      - name: Wait for NGINX admission webhook endpoints
        shell: bash
        run: |
          set -euo pipefail
          # Wait for the admission deployment
          kubectl -n ingress-nginx rollout status deploy/ingress-nginx-controller-admission --timeout=180s || true

          # Wait until the Service has at least one ready endpoint
          ATTEMPTS=40
          until kubectl -n ingress-nginx get endpoints ingress-nginx-controller-admission \
                -o jsonpath='{.subsets[0].addresses[0].ip}' 2>/dev/null | grep -qE '.'; do
            ((ATTEMPTS--)) || { echo "Admission webhook endpoints not ready"; kubectl -n ingress-nginx get all -o wide; exit 1; }
            echo "Waiting for admission webhook endpoints…"
            sleep 5
          done
          echo "Admission webhook is ready."

      - name: Enforce repo-server Service selector & Ingress
        shell: bash
        run: |
          set -euo pipefail
          kubectl apply -f infra/overrides/argocd-repo-server-svc.yaml
          kubectl apply -f infra/overrides/argo-ingress.yaml   # now safe; webhook is ready
          kubectl -n argocd patch svc argocd-repo-server --type='json' -p='[
            {"op":"remove","path":"/spec/selector/app.kubernetes.io~1instance"}
          ]' || true
          kubectl -n argocd delete endpoints argocd-repo-server --ignore-not-found || true
          for i in {1..30}; do
            ES="$(kubectl -n argocd get endpointslice -l kubernetes.io/service-name=argocd-repo-server -o json || true)"
            if echo "$ES" | grep -q '"addresses":\s*\['; then
              echo "EndpointSlice populated."
              break
            fi
            echo "Waiting for EndpointSlice… ($i/30)"
            sleep 2
          done
          kubectl -n argocd get svc argocd-repo-server -o jsonpath='{.spec.selector}{"\n"}'    

  # ----------------------------------------------------------
  # Deploy to local minikube with Argo CD (App-of-Apps)
  # ----------------------------------------------------------
  k8s-argocd-minikube:

    name: Minikube + Argo CD (App-of-Apps)
    runs-on: [ self-hosted, macOS ]
    needs: [ resolve-target, resolve-build-mode, prepare-minikube ]
    if: ${{ needs.resolve-target.outputs.target == 'mac' && (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/tags/')) }}
    env:
      TAG: ${{ needs.resolve-build-mode.outputs.IMAGE_TAG }}
      ARGO_NS: argocd
    steps:
      - uses: actions/checkout@v4

      - name: Adopt app namespaces to Helm ownership (idempotent)
        shell: bash
        env:
          RELEASE_NAME: argocd-apps
          CHART_NS: ${{ env.ARGO_NS }}
        run: |
          set -euo pipefail
          adopt() {
            local ns="$1"
            if kubectl get ns "$ns" >/dev/null 2>&1; then
              echo "Adopting namespace '$ns' to Helm release ${RELEASE_NAME} in ${CHART_NS}…"
              kubectl annotate namespace "$ns" \
                meta.helm.sh/release-name="${RELEASE_NAME}" \
                meta.helm.sh/release-namespace="${CHART_NS}" \
                --overwrite
              kubectl label namespace "$ns" app.kubernetes.io/managed-by=Helm --overwrite
            else
              echo "Namespace '$ns' does not exist (Helm will create it if needed)."
            fi
          }
          adopt mario-backend
          adopt mario-web
          adopt monitoring

      - name: Install/Upgrade App-of-Apps (Helm)
        shell: bash
        run: |
          set -euo pipefail
          helm upgrade --install argocd-apps ./infra/helm/argocd-apps -n "${ARGO_NS}" --create-namespace \
            -f ./infra/helm/argocd-apps/values.yaml \
            --set project.enabled=false \
            --set global.releaseTag="${TAG}" \
            --wait
          helm -n "${ARGO_NS}" status argocd-apps || true

      - name: Show Applications & Ingresses (debug)
        shell: bash
        run: |
          set -euo pipefail
          kubectl -n "${ARGO_NS}" get applications.argoproj.io -o wide || true
          echo "---- argocd ingress ----"
          kubectl -n argocd get ingress || true
          echo "---- web/back/monitoring ingresses ----"
          kubectl -n mario-web get ingress || true
          kubectl -n mario-backend get ingress || true
          kubectl -n monitoring get ingress || true

      - name: Wait for ArgoCD Ingress host to be admitted
        shell: bash
        run: |
          set -euo pipefail
          ATTEMPTS=30
          until kubectl -n argocd get ingress 2>/dev/null | grep -q 'argo.mario.local'; do
            ((ATTEMPTS--)) || { echo "ArgoCD ingress not found"; exit 1; }
            echo "waiting for ArgoCD ingress…"
            sleep 6
          done
          echo "ArgoCD ingress:"
          kubectl -n argocd get ingress -o wide

      - name: Wait for ingress controller & discover NodePort
        shell: bash
        run: |
          set -euo pipefail

          # 1) Wait for ingress controller pods to be ready
          kubectl -n ingress-nginx rollout status deploy/ingress-nginx-controller --timeout=180s

          # 2) Wait for endpoints (controller has a ready pod behind the service)
          ATTEMPTS=30
          until kubectl -n ingress-nginx get endpoints ingress-nginx-controller -o jsonpath='{.subsets[0].addresses[0].ip}' 2>/dev/null | grep -qE '.'; do
            ((ATTEMPTS--)) || { echo "No endpoints for ingress-nginx-controller"; kubectl -n ingress-nginx get all -o wide; exit 1; }
            echo "Waiting for ingress-nginx-controller endpoints…"
            sleep 5
          done

          # 3) Discover NodePort for HTTP (80)
          export MK_IP="$(minikube ip)"
          export HTTP_NODEPORT="$(kubectl -n ingress-nginx get svc ingress-nginx-controller -o jsonpath='{.spec.ports[?(@.port==80)].nodePort}')"
          echo "MINIKUBE_IP=${MK_IP}"
          echo "HTTP_NODEPORT=${HTTP_NODEPORT}"

          # 4) Quick sanity: is the nodeport open?
          if command -v nc >/dev/null 2>&1; then
            if ! nc -z "${MK_IP}" "${HTTP_NODEPORT}"; then
              echo "::warning::NodePort ${HTTP_NODEPORT} not open yet on ${MK_IP}. Continuing; curl step may retry."
            fi
          fi

          # Export for next step
          {
            echo "MK_IP=${MK_IP}"
            echo "HTTP_NODEPORT=${HTTP_NODEPORT}"
          } >> "$GITHUB_ENV"

      - name: Smoke test Ingress (host->cluster) with fallback to in-cluster curl
        shell: bash
        run: |
          set +e
          which curl >/dev/null 2>&1 || { echo "curl not found; skipping"; exit 0; }
          
          echo "Testing via host (NodePort) — expect 200/301/307"
          for h in web.mario.local api.mario.local argo.mario.local; do
            echo "== $h =="
            # Try NodePort on MINIKUBE_IP
            curl -sS -I --max-time 10 -H "Host: $h" "http://${MK_IP}:${HTTP_NODEPORT}" || echo "host->${MK_IP}:${HTTP_NODEPORT} failed for $h"
            echo
          done
          
          echo "If host tests failed, try in-cluster curl (always validates routing inside the cluster)"
          kubectl -n kube-system delete pod curl-tester --ignore-not-found
          kubectl -n kube-system run curl-tester --restart=Never --image=curlimages/curl:8.10.1 -- sleep 120 &
          # Wait for the pod to be running
          kubectl -n kube-system wait --for=condition=Ready pod/curl-tester --timeout=60s || true
          
          for h in web.mario.local api.mario.local argo.mario.local; do
            echo "== in-cluster: $h =="
            kubectl -n kube-system exec curl-tester -- sh -lc \
              "curl -sS -I --max-time 10 -H 'Host: ${h}' http://ingress-nginx-controller.ingress-nginx.svc.cluster.local" \
              || echo "in-cluster curl failed for $h"
            echo
          done
          
          # Cleanup (best effort)
          kubectl -n kube-system delete pod curl-tester --ignore-not-found || true
          
      - name: Ensure apps are Synced (CLI)
        shell: bash
        run: |
          set -euo pipefail
          # lightweight install
          curl -sSL -o argocd \
            https://github.com/argoproj/argo-cd/releases/download/v2.10.7/argocd-linux-amd64
          chmod +x argocd

          ARGO_SERVER="argocd-server.argocd.svc.cluster.local"
          # With server.insecure=true we can do this:
          ./argocd login "${ARGO_SERVER}" --insecure \
            --username admin \
            --password "$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d)" \
            || true

          for app in argocd backend web keda monitoring; do
            ./argocd app sync "$app" --prune --timeout 300 || true
            ./argocd app wait "$app" --timeout 180 || true
          done

  # ----------------------------------------------------------
  # Slack summaries (global + minikube-only) and sender
  # ----------------------------------------------------------
  summarize-status:
    name: Summarize results for Slack
    if: ${{ always() }}
    runs-on: ubuntu-latest
    needs:
      - resolve-target
      - resolve-build-mode
      - build-and-push-app
      - build-and-push-web
      - snyk-release
      - mirror-to-nexus
      - prepare-minikube
      - deploy-mac
      - deploy-ec2
    outputs:
      status: ${{ steps.sum.outputs.status }}
      message: ${{ steps.sum.outputs.message }}
    env:
      TARGET: ${{ needs.resolve-target.outputs.target || 'mac' }}
      BUILD_IMAGES: ${{ needs.resolve-build-mode.outputs.BUILD_IMAGES || 'true' }}
      RES_BUILD_APP: ${{ needs['build-and-push-app'].result   || 'skipped' }}
      RES_BUILD_WEB: ${{ needs['build-and-push-web'].result   || 'skipped' }}
      RES_SNYK: ${{ needs['snyk-release'].result         || 'skipped' }}
      RES_MIRROR: ${{ needs['mirror-to-nexus'].result      || 'skipped' }}
      RES_PREP: ${{ needs['prepare-minikube'].result     || 'skipped' }}
      RES_DEPLOY_MAC: ${{ needs['deploy-mac'].result          || 'skipped' }}
      RES_DEPLOY_EC2: ${{ needs['deploy-ec2'].result          || 'skipped' }}
    steps:
      - id: sum
        name: Build Slack status/message
        if: ${{ always() }}
        shell: bash
        run: |
          # Make this step non-fatal regardless of any non-zero exits.
          set +e
          # Keep "unset var" strictness and pipefail, but not -e:
          set -u -o pipefail

          note=""
          if [[ "${BUILD_IMAGES:-true}" != "true" ]]; then
            note="(builds skipped; using existing images)"
          fi

          failures=()
          add_if_fail () { local n="$1" v="${2:-}"; [[ "$v" == "failure" ]] && failures+=("$n"); }

          add_if_fail "build-and-push-app" "${RES_BUILD_APP:-skipped}"
          add_if_fail "build-and-push-web" "${RES_BUILD_WEB:-skipped}"
          add_if_fail "snyk-release"       "${RES_SNYK:-skipped}"

          if [[ "${TARGET:-mac}" == "mac" ]]; then
            add_if_fail "mirror-to-nexus"     "${RES_MIRROR:-skipped}"
            add_if_fail "prepare-minikube"    "${RES_PREP:-skipped}"
            add_if_fail "deploy-mac"          "${RES_DEPLOY_MAC:-skipped}"
            # add_if_fail "k8s-argocd-minikube" "${RES_ARGO_MINI:-skipped}"  # include if you wire it in needs/env
          else
            add_if_fail "deploy-ec2"          "${RES_DEPLOY_EC2:-skipped}"
          fi

          if ((${#failures[@]})); then
            echo "status=failure" >>"$GITHUB_OUTPUT"
            printf 'message=%s\n' "❌ Failed steps: ${failures[*]} · target=${TARGET:-?} ${note}" >>"$GITHUB_OUTPUT"
          else
            echo "status=success" >>"$GITHUB_OUTPUT"
            printf 'message=%s\n' "✅ All steps succeeded · target=${TARGET:-?} ${note}" >>"$GITHUB_OUTPUT"
          fi

          # Force success so Slack can still send
          exit 0

  notify-slack:
    name: notify-slack / send
    if: ${{ always() }}
    needs:
      - summarize-status     # <— only the aggregator
    uses: tAIness/devops-ci-lib/.github/workflows/slack-notify.yml@main
    secrets: inherit
    with:
      title: "Release: ${{ needs.summarize-status.outputs.status == 'success' && (github.ref_type == 'tag' && github.ref_name || needs.resolve-build-mode.outputs.IMAGE_TAG) || (needs.resolve-build-mode.outputs.IMAGE_TAG || github.ref_name) }}"
      status: ${{ needs.summarize-status.outputs.status }}
      only_on: "always"
      run_url: "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
      message: "${{ needs.summarize-status.outputs.message }}"
